{"_default": {"1": {"name": "test paper", "source": "online", "datePublished": "1995-08-19", "dateRead": "2019-06-25", "comments": "# Test header\r\nsomething under the header\r\n\r\n1. a numbered\r\n1. list for\r\n1. markdown checking\r\n\r\n- and a bunch of\r\n- regular\r\n- list items\r\n- down here\r\n\r\n### Smaller header\r\nyup\r\n\r\n# and a big header\r\nim done now", "type": "paper"}, "2": {"name": "Black-box Generation of Adversarial Text Sequences to Evade Deep Learning Classifiers", "source": "QData", "datePublished": "2018-05-23", "dateRead": "2019-05-31", "comments": "- Categorizing NLPAE techniques: (1) targeted/untargeted? (2) choice of \u0394 (3) black-box or white-box?\r\n- Unlike images, text data is discrete, so it is hard to define \u0394x (main issue: is 'a' closer to 'b' than 'c'? no. but #000 is closer to #111 than #fff)\r\n- I did not know that CNNs worked so well on text data!\r\n\r\n### Adversarial Sequence Generation:\r\n(1) Score characters to figure out which are most important\r\n    - four scoring methods: Replace-1, Temporal Head, Temporal Tail, Temporal Head+Tail\r\n(2) transform into slightly different characters to form a new sequence that fools the classifier; basically just replace words with 'unknown'\r\n     - four techniques for this: swap two letters, substitute letter, delete letter, insert letter\r\n\r\n- DeepWordBug works well; is black-box; and it is fast", "type": "paper"}}}